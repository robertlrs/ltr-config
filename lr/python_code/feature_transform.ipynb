{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "import json\n",
    "import codecs\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished\n"
     ]
    }
   ],
   "source": [
    "def user_province(spark):\n",
    "    provinces = spark.sql(\"select distinct province from songwt.lr_sample where label=1 and country='中国'\").collect()\n",
    "    _list = [\"uCity=%s\" % row.province for row in provinces]\n",
    "    _list.append(\"uCity=国外\")\n",
    "    _list.append(\"uCity=others\")\n",
    "    return _list\n",
    "\n",
    "def item_city(spark):\n",
    "    city = spark.sql(\"SELECT new_city, row_number() OVER(ORDER BY new_city) as num from (SELECT DISTINCT new_city from songwt.city_normalize) t\").collect()\n",
    "    _list = [int(row.num) for row in city]\n",
    "    _max = max(_list)\n",
    "    _list2 = []\n",
    "    for ln in _list:\n",
    "        _list2.append(\"province=%d\" % ln)\n",
    "    \n",
    "    _list2.append(\"province=0\")\n",
    "    return [_list2, _max]\n",
    "\n",
    "def craftsman(spark):\n",
    "    seller = spark.sql(\"select uid from features.craftsman_profile\").collect()\n",
    "    _list = [int(row.uid) for row in seller]\n",
    "    _max = max(_list)\n",
    "    _list2 = []\n",
    "    for ln in _list:\n",
    "        _list2.append(\"hashUid=%d\" % ln)\n",
    "    _list2.append(\"hashUid=0\")\n",
    "    return [_list2, _max]\n",
    "\n",
    "def item_cid(spark):\n",
    "    cid = spark.sql(\"SELECT id from kaipao.dj_category\").collect()\n",
    "    _list = [int(row.id) for row in cid]\n",
    "    _max = max(_list)\n",
    "    _list2 = []\n",
    "    for ln in _list:\n",
    "        _list2.append(\"categoryId=%d\" % ln)\n",
    "    _list2.append(\"categoryId=0\")\n",
    "    return [_list2, _max]\n",
    "\n",
    "def item_pid(spark):\n",
    "    pid = spark.sql(\"SELECT DISTINCT parent_id from kaipao.dj_category\").collect()\n",
    "    _list = [int(row.parent_id) for row in pid]\n",
    "    _list2 = []\n",
    "    _max = max(_list)\n",
    "    for ln in _list:\n",
    "        _list2.append(\"parentCategoryId=%d\" % ln)\n",
    "    return [_list2,_max]\n",
    "\n",
    "def item_kind():\n",
    "    _list = [\"kind=%d\" % i for i in range(0,49)]\n",
    "    return [_list, 48]\n",
    "\n",
    "\n",
    "\n",
    "def main(spark):\n",
    "    ctr = [(\"reItemCtr=0\",0,0.075),(\"reItemCtr=1\",0.075,0.08730159),(\"reItemCtr=2\",0.08730159,0.09428571),(\"reItemCtr=3\",0.09428571, 0.09803922),\n",
    "              (\"reItemCtr=4\",0.09803922,0.1015625),(\"reItemCtr=5\",0.1015625,0.11111111),(\"reItemCtr=6\",0.11111111,0.11956522),\n",
    "           (\"reItemCtr=7\",0.11956522,0.13461538),(\"reItemCtr=8\",0.13461538,0.15957447),(\"reItemCtr=9\",0.15957447,1)]\n",
    "    collect=[(\"collectInterval=0\",0,0),(\"collectInterval=1\",0,1),(\"collectInterval=2\",1,3),(\"collectInterval=3\",3,16),(\"collectInterval=4\",16,10000)]\n",
    "    addcart=[(\"addcartInterval=0\",0,0),(\"addcartInterval=1\",0,1),(\"addcartInterval=2\",1,2),(\"addcartInterval=3\",2,3),(\"addcartInterval=4\", 3, 10000)]\n",
    "    grade=[\"categoryGrade=0\",\"categoryGrade=1\",\"categoryGrade=2\",\"categoryGrade=3\",\"categoryGrade=4\",\"categoryGrade=5\"]\n",
    "    sale = [(\"sellcntInterval=0\",0,0),(\"sellcntInterval=1\",0,1),(\"sellcntInterval=2\",1,2),(\"sellcntInterval=3\",2,3),(\"sellcntInterval=4\",4,10000)]\n",
    "    _type = [\"uType=0\",\"uType=1\"]\n",
    "    preferencekind = [\"preferenceKind=0\", \"preferenceKind=1\"]\n",
    "    preferencecategory = [\"preferenceCategory=0\", \"preferenceCategory=1\"]\n",
    "    \n",
    "    features = list()\n",
    "    \n",
    "    for _input in [user_province(spark), _type]:\n",
    "        for idx, name in enumerate(_input):\n",
    "            feature = dict()\n",
    "            fe = name.split(\"=\")[0]\n",
    "            feature[\"name\"] = name\n",
    "            feature[\"type\"] = \"categorical\"\n",
    "            feature[\"channel\"] = \"input\"\n",
    "            feature[\"index\"] = idx\n",
    "            feature[\"max\"] = 2\n",
    "            feature[\"field\"] = fe\n",
    "            feature[\"field_type\"] = \"string\"\n",
    "            feature[\"params\"] = [fe]\n",
    "            feature[\"template_language\"] = \"mustache\"\n",
    "            feature[\"template\"] = {\"function_score\":{\"field_value_factor\":{\"field\":fe,\"missing\":0}}}\n",
    "            features.append(feature)\n",
    "    \n",
    "    for query in [item_cid(spark), item_pid(spark), item_kind(), craftsman(spark), item_city(spark)]:\n",
    "        query1 = query[0]\n",
    "        _max = query[1]\n",
    "        for idx, name in enumerate(query1):\n",
    "            feature = dict()\n",
    "            fe = name.split(\"=\")[0]\n",
    "            feature[\"name\"] = name\n",
    "            feature[\"type\"] = \"categorical\"\n",
    "            feature[\"channel\"] = \"query\"\n",
    "            feature[\"index\"] = idx\n",
    "            feature[\"max\"] = _max\n",
    "            feature[\"field\"] = fe\n",
    "            feature[\"field_type\"] = \"int\"\n",
    "            feature[\"template_language\"] = \"mustache\"\n",
    "            feature[\"template\"] = {\"function_score\":{\"field_value_factor\":{\"field\":fe,\"missing\":0}}}\n",
    "            features.append(feature)\n",
    "        \n",
    "    for query in [grade]:\n",
    "        for idx, name in enumerate(query):\n",
    "            feature = dict()\n",
    "            fe = name.split(\"=\")[0]\n",
    "            feature[\"name\"] = name\n",
    "            feature[\"type\"] = \"categorical\"\n",
    "            feature[\"channel\"] = \"query\"\n",
    "            feature[\"index\"] = idx\n",
    "            feature[\"max\"] = 5\n",
    "            feature[\"field\"] = fe\n",
    "            feature[\"field_type\"] = \"int\"\n",
    "            feature[\"template_language\"] = \"mustache\"\n",
    "            feature[\"template\"] = {\"function_score\":{\"field_value_factor\":{\"field\":fe,\"missing\":0}}}\n",
    "            features.append(feature)\n",
    "            \n",
    "    for query in [collect, addcart, sale]:\n",
    "        for idx, name in enumerate(query):\n",
    "            feature = dict()\n",
    "            fea = name[0]\n",
    "            fe = fea.split(\"=\")[0]\n",
    "            dayu = name[1]\n",
    "            xiaoyu = name[2]\n",
    "            feature[\"name\"] = fea\n",
    "            feature[\"type\"] = \"range\"\n",
    "            feature[\"channel\"] = \"query\"\n",
    "            feature[\"index\"] = idx\n",
    "            feature[\"max\"] = len(query)-1\n",
    "            feature['field'] = fe\n",
    "            feature[\"field_type\"] = \"float\"\n",
    "            feature[\"template_language\"] = \"mustache\"\n",
    "            if idx == 0:\n",
    "                feature[\"template\"] = {\"range\":{fe:{\"gte\":0, \"lte\":0}}}\n",
    "            else:\n",
    "                feature[\"template\"] = {\"range\":{fe:{\"gt\":dayu, \"lte\":xiaoyu}}}\n",
    "            features.append(feature)\n",
    "            \n",
    "    for query in [ctr]:\n",
    "        for idx, name in enumerate(query):\n",
    "            feature = dict()\n",
    "            fea = name[0]\n",
    "            fe = fea.split(\"=\")[0]\n",
    "            dayu = name[1]\n",
    "            xiaoyu = name[2]\n",
    "            feature[\"name\"] = fea\n",
    "            feature[\"type\"] = \"range\"\n",
    "            feature[\"channel\"] = \"query\"\n",
    "            feature[\"index\"] = idx\n",
    "            feature[\"max\"] = len(query)-1\n",
    "            feature['field'] = fe\n",
    "            feature[\"field_type\"] = \"float\"\n",
    "            feature[\"template_language\"] = \"mustache\"\n",
    "            feature[\"template\"] = {\"range\":{fe:{\"gt\":dayu, \"lte\":xiaoyu}}}\n",
    "            features.append(feature)\n",
    "            \n",
    "    for binary in [preferencekind, preferencecategory]:\n",
    "        for idx, name in enumerate(binary):\n",
    "            feature = dict()\n",
    "            fe = name.split(\"=\")[0]\n",
    "            feature[\"name\"] = name\n",
    "            feature[\"type\"] = \"categorical\"\n",
    "            feature[\"channel\"] = \"binary\"\n",
    "            feature[\"index\"] = idx\n",
    "            feature[\"max\"] = len(binary)-1\n",
    "            feature[\"field\"] = fe\n",
    "            feature[\"field_type\"] = \"int\"\n",
    "            feature[\"params\"] = [fe]\n",
    "            feature[\"template_language\"] = \"mustache\"\n",
    "            if fe == \"preferenceKind\":\n",
    "                field = \"kind\"\n",
    "            else:\n",
    "                field = \"categoryId\"\n",
    "            feature[\"template\"] = {\"function_score\":{\"field_value_factor\":{\"field\":field, \"missing\":0}}}\n",
    "            features.append(feature)\n",
    "            \n",
    "    _finally = {\"validation\":{\"params\":{\"uCity\":\"浙江省\",\"uType\":0,\"preferenceCategory\":[781], \"preferenceKind\":[1,2]},\"index\":\"item\"},\n",
    "                \"featureset\":{\"features\":features}}\n",
    "    f = open(\"lr_features.json\", \"w\")\n",
    "    json.dump(_finally, f)\n",
    "    print(\"finished\")\n",
    "    \n",
    "    \n",
    "\n",
    "def test(spark):\n",
    "    _list = list()\n",
    "    for ln in codecs.open(\"1.txt\", \"rb\"):\n",
    "        ln = ln.strip().decode(\"utf8\")\n",
    "        lnn = ln.split(\"\\t\")\n",
    "        name = lnn[0]\n",
    "        value = lnn[1]\n",
    "        if name == \"uid\":\n",
    "            _list.append((value, value))\n",
    "    print(_list)\n",
    "    df = spark.createDataFrame(_list, ['sellerid', 'hashuid'])\n",
    "    df.write.format(\"parquet\").mode(\"overwrite\").saveAsTable(\"features.lr_hashuid\")\n",
    "    print(\"finished\")\n",
    "    \n",
    "            \n",
    "\n",
    "    \n",
    "    \n",
    "            \n",
    "    \n",
    "            \n",
    "    \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    spark = SparkSession.builder.appName(\"lr_sample_train\").getOrCreate()\n",
    "    main(spark)\n",
    "    #item_cid(spark)\n",
    "    #test(spark)\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
